import os
import os.path
import logging
import multiprocessing
import sys
import numpy as np
from netCDF4 import Dataset


def calcola_stress(prefix, current, nextt, root_lavoro, tipo_dati, var_name, z_type):

    file_path = f"{root_lavoro}/{prefix}.atmos_{tipo_dati}_Ls{current}_{nextt}_{z_type}_sel.nc"
    logging.debug(f"* calcola_stress {file_path=}")
    ds = Dataset(file_path, 'r+')  # Apertura in modalitÃ  lettura e scrittura

    z = ds.variables[z_type][:]
    u = ds.variables['ucomp'][:]
    v = ds.variables['vcomp'][:]
    rho = ds.variables['rho_f'][:]

    #selected_z = [15, 30, 50]
    selected_z = [15, 30]
    selected_indices = [np.argmin(np.abs(z - sz)) for sz in selected_z]  # Indici delle quote


    u_selected = u[:, :, selected_indices, :, :]
    v_selected = v[:, :, selected_indices, :, :]

    shear_u = np.zeros((u.shape[0], u.shape[1], u.shape[3], u.shape[4]))
    shear_v = np.zeros((v.shape[0], v.shape[1], v.shape[3], v.shape[4]))

    for t in range(u.shape[0]):  # Tempo
        for tod in range(u.shape[1]):  # Ora del giorno
         for i in range(u.shape[3]):  # Latitudine
                for j in range(u.shape[4]):  # Longitudine
                    # Profili verticali di u e v per le quote selezionate
                    z_subset = np.array(selected_z)
                    u_profile = u_selected[t, tod, :, i, j]
                    v_profile = v_selected[t, tod, :, i, j]

                    # Filtra i dati validi
                    valid_u = ~np.isnan(u_profile)
                    valid_v = ~np.isnan(v_profile)

                    # Regressione lineare su u
                    if np.sum(valid_u) > 1:
                        z_u = z_subset[valid_u]
                        u_u = u_profile[valid_u]
                        z_mean_u = np.mean(z_u)
                        u_mean = np.mean(u_u)
                        shear_u[t, tod, i, j] = np.sum((z_u - z_mean_u) * (u_u - u_mean)) / np.sum((z_u - z_mean_u) ** 2)
                    else:
                        shear_u[t, tod, i, j] = np.nan

                    # Regressione lineare su v
                    if np.sum(valid_v) > 1:
                        z_v = z_subset[valid_v]
                        v_v = v_profile[valid_v]
                        z_mean_v = np.mean(z_v)
                        v_mean = np.mean(v_v)
                        shear_v[t, tod, i, j] = np.sum((z_v - z_mean_v) * (v_v - v_mean)) / np.sum((z_v - z_mean_v) ** 2)
                    else:
                        shear_v[t, tod, i, j] = np.nan

    logging.debug("Calcolo della magnitudine dello shear")
    shear_magnitude = np.sqrt(shear_u**2 + shear_v**2)

    stress = rho * shear_magnitude**2

    logging.debug("Aggiungi la variabile stress al dataset e salva")
    # if 'stress' not in ds.variables:
    # stress_var = ds.createVariable('stress', 'f4', ('time', 'time_of_day_24', 'lat', 'lon'), fill_value=np.nan)
    stress_var = ds.createVariable(var_name, 'f4', ('time', 'time_of_day_24', 'lat', 'lon'), fill_value=np.nan)
    stress_var.units = "Pa"
    stress_var.long_name = "Wind stress"
    #else:
    #    stress_var = ds.variables['stress']

    stress_var[:] = stress
    logging.debug("Chiudi il file NetCDF")
    ds.close()


class AddStress():
    def __init__(self, report, **env):
        """ Split atmos_daily simulation datafile to fit memory constraints.

        Args:
            max_threads (int, optional): _description_. Defaults to 5.
        """
        self.env = env
        logging.debug(f"class AddStress(), {self.env=}")
        
        sol_file_dati = self.env['sol_file_dati']
        root_lavoro = self.env['root_lavoro']
        periodi = self.env['periodi']
        if self.env['var_name']:
            var_name = self.env['var_name']
        else:
            var_name = 'stress'

        if os.cpu_count() <= int(self.env['max_threads'] + 1):
            self.env['max_threads'] = os.cpu_count() - 1

        tipo_dati = self.env['out_type']
        z_type = self.env['z_type']

        report_header = self.__class__.__name__
        report_msg = ""

        pool = multiprocessing.Pool(processes=self.env['max_threads'])
        tasks = []

        try:
            for i in range(len(periodi) - 1):  
                current = periodi[i]
                nextt = periodi[i + 1]
                
                files = [f for f in os.listdir(root_lavoro) if f.endswith(f"atmos_{tipo_dati}_Ls{current}_{nextt}.nc")]
                for file in files:
                    prefix = file.split('.')[0]

                logging.debug(f"Aggiungo task per  {prefix=} {current=} e {nextt=}")

                tasks.append(pool.apply_async(calcola_stress, args=(prefix, current, nextt, root_lavoro, tipo_dati, var_name, z_type)))

            pool.close()

            for task in tasks:
                task.get()
        
        except Exception as e:
            logging.error(f"Errore durante l'elaborazione: {e}")
            err = 1
            raise Exception(f"{e.stderr}")
        finally:
            pool.join()


